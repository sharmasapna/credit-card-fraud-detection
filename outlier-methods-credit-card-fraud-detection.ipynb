{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the packages\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import sklearn.exceptions\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import OneClassSVM\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from imblearn.under_sampling import NearMiss \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129668, 23) (27786, 23)\n",
      "(129668, 17) (27786, 17)\n",
      "(129668, 16) (129668,) (27786, 16) (27786,)\n",
      "(129668, 16) (27786, 16)\n",
      "merchant\n",
      "category\n",
      "gender\n",
      "street\n",
      "city\n",
      "state\n",
      "job\n",
      "(129668, 3077) (27786, 3077)\n",
      "0    128963\n",
      "1       705\n",
      "Name: is_fraud, dtype: int64 \n",
      " 0    27656\n",
      "1      130\n",
      "Name: is_fraud, dtype: int64\n",
      "(129668, 3077) (27786, 3077) (129668,) (27786,)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "data_train = pd.read_csv(\"fraudTrain.csv\")\n",
    "data_test = pd.read_csv(\"fraudTest.csv\")\n",
    "# taking smaller sample to run the model faster\n",
    "\n",
    "df_train= data_train.sample(frac = 0.1,random_state=1)\n",
    "df_test= data_test.sample(frac = 0.05,random_state=1)\n",
    "print(df_train.shape,df_test.shape)\n",
    "# function to drop tbe columns\n",
    "def dropCol(data):\n",
    "    col_to_drop = ['trans_date_trans_time','Unnamed: 0','cc_num','first','last','trans_num']\n",
    "    res = data.drop(col_to_drop,axis = 1)\n",
    "    return res\n",
    "# dropping the columns\n",
    "# dropping the columns ['trans_date_trans_time','Unnamed: 0','cc_num','first','last','trans_num']\n",
    "# train data set\n",
    "df_train = dropCol(df_train)\n",
    "# test data set\n",
    "df_test = dropCol(df_test)\n",
    "\n",
    "print ( df_train.shape, df_test.shape)\n",
    "\n",
    "#Create independent and Dependent Features\n",
    "columns = df_train.columns.tolist()\n",
    "\n",
    "# removing the dependent feature is_fraud\n",
    "columns = [c for c in columns if c not in [\"is_fraud\"]]\n",
    "\n",
    "X_train = df_train[columns]\n",
    "Y_train = df_train['is_fraud']\n",
    "X_test = df_test[columns]\n",
    "Y_test = df_test['is_fraud']\n",
    "print ( X_train.shape, Y_train.shape,X_test.shape, Y_test.shape)\n",
    "\n",
    "# function to convert dob to years\n",
    "def age_years(born):\n",
    "    return 2019 - int(born[0:4])\n",
    "\n",
    "# replacing the dob column with age column in our data set for test and train\n",
    "X_train['age'] = X_train['dob'].apply(lambda x: age_years(x))\n",
    "X_train = X_train.drop(['dob'],axis =1)\n",
    "\n",
    "X_test['age'] = X_test['dob'].apply(lambda x: age_years(x))\n",
    "X_test = X_test.drop(['dob'],axis =1)\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "# concanating the test and train data so that number of columns remain the same in both the data sets\n",
    "final_df = pd.concat([X_train,X_test],axis=0)\n",
    "final_df.shape\n",
    "\n",
    "\n",
    "# creating the list of categorical variables\n",
    "categorical_features =[feature for feature in X_train.columns if final_df[feature].dtypes == 'O']\n",
    "categorical_features\n",
    "\n",
    "# function to convert categorical variables to one hot encoding\n",
    "def category_onehot_multcols(data,multcolumns):\n",
    "    df_final = data\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:           \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1             \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "    return df_final\n",
    "\n",
    "# applying the one hot encoding\n",
    "final_df = category_onehot_multcols(final_df, categorical_features)\n",
    "\n",
    "# removing duplicated columns\n",
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]\n",
    "final_df.shape\n",
    "\n",
    "# separating the test and training data\n",
    "df_Train=final_df.iloc[:129668,:]\n",
    "df_Test=final_df.iloc[129668:,:]\n",
    "print(df_Train.shape,df_Test.shape)\n",
    "\n",
    "print(Y_train.value_counts(),\"\\n\",Y_test.value_counts())\n",
    "\n",
    "# files ready for testing on models\n",
    "print(df_Train.shape, df_Test.shape, Y_train.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's evaluate our model \n",
    "def print_eval(y_pred,model):\n",
    "    print(\"Training Accuracy: \",model.score(df_Train, Y_train))\n",
    "    print(\"Testing Accuracy: \", model.score(df_Test, Y_test))\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(classification_report(Y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train_copy = df_Train.copy()\n",
    "df_Test_copy = df_Test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "### 5.  Considering the Fraud cases as anamoly and use anamoly detection methods such as:   \n",
    "> 5.1 Simple Statistical Methods : Metrics such as distribution, including mean, median, mode, and quantiles could be used to identify outliers since the definition of an anomalous data point is one that deviates by a certain standard deviation from the mean.    \n",
    "5.2 Density-Based Anomaly Detection : These include the    \n",
    "> 5.2.1 k-nearest neighbors algorithm   \n",
    "5.2.2 Relative density of data based method known as local outlier factor (LOF) algorithm **(Implemented)**   \n",
    "5.3 Isolation Forest **(Implemented)**   \n",
    "5.4 Clustering-Based Anomaly Detection : K-means algorithm  \n",
    "5.5 Support Vector Machine-Based Anomaly Detection          \n",
    "5.6 Using Auto Encoders **(Implemented)**       \n",
    "5.7 Neural Network  (Same as Autoencoders? ???)  \n",
    "5.8 OneClassSVM    \n",
    "5.9 DBSCAN    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Simple Statistical Methods \n",
    "Metrics such as distribution, including mean, median, mode, and quantiles could be used to identify outliers since the definition of an anomalous data point is one that deviates by a certain standard deviation from the mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper and lower limit calculation with z score method and handling out liers\n",
    "#data = pd.read_csv('machine_0.csv',index_col=0)\n",
    "def handle_outlier(data):\n",
    "\"\"\"The function takes the data and replaces all the outlier values o f all columns\n",
    "with '0000000001' \"\"\"\n",
    "data_outlier_handled = data.copy() \n",
    "column_names = data.columns \n",
    "total_outliers = []\n",
    "for col in column_names:\n",
    "t=0\n",
    "upper_boundary = data_outlier_handled[col].mean() + 3 * data_out lier_handled[col].std()\n",
    "lower_boundary = data_outlier_handled[col].mean() - 3 * data_out lier_handled[col].std()\n",
    "data_outlier_handled.loc[data_outlier_handled[col] > upper_bound ary,col] = 0.0000000001\n",
    "data_outlier_handled.loc[data_outlier_handled[col] < lower_bound ary,col] = 0.0000000001\n",
    "tu = data[data[col] > upper_boundary].count()[1] tl = data[data[col] < lower_boundary].count()[1]\n",
    "#total_outliers.append(round((tu+tl)/len(data),2)) #to calculate the percent of outliers handled\n",
    "#print(total_outliers) #to print the percent of outliers handled\n",
    "return data_outlier_handled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2  Local Outlier Factor  \n",
    "Density-Based Anomaly Detection : These include the k-nearest neighbors algorithm, Relative density of data based method known as local outlier factor (LOF) algorithm \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgement\n",
    "https://medium.com/datadriveninvestor/credit-card-fraud-detection-using-local-outlier-factor-and-isolation-forest-in-python-56edd0a44af5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal cases in train set : 128963 \n",
      "Fraud cases in train set : 705\n",
      "Normal cases in test set : 27656 \n",
      "Fraud cases in test set : 130\n",
      "Fraud percentage : 0.0054\n",
      "Fraud percentage : 0.004678615129921543\n"
     ]
    }
   ],
   "source": [
    "## Get the Fraud and the normal  transaction numbers for test and train dataset \n",
    "\n",
    "fraud_train = df_train[df_train['is_fraud']==1]\n",
    "normal_train = df_train[df_train['is_fraud']==0]\n",
    "fraud_test = df_test[df_test['is_fraud']==1]\n",
    "normal_test = df_test[df_test['is_fraud']==0]\n",
    "\n",
    "print(\"Normal cases in train set :\",len(df_train)-len(fraud_train),\"\\nFraud cases in train set :\",len(fraud_train))\n",
    "print(\"Normal cases in test set :\",len(df_test)-len(fraud_test),\"\\nFraud cases in test set :\",len(fraud_test))\n",
    "outlier_fraction = round(len(fraud_train)/len(df_train),4)\n",
    "print(\"Fraud percentage :\", outlier_fraction)\n",
    "print(\"Fraud percentage :\", len(fraud_test)/len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129668, 3077) (27786, 3077) (129668,) (27786,)\n"
     ]
    }
   ],
   "source": [
    "# preprocssed files for our use\n",
    "print(df_Train.shape, df_Test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394\n",
      "0.9892494678717957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    128967\n",
      "           1       0.01      0.01      0.01       701\n",
      "\n",
      "    accuracy                           0.99    129668\n",
      "   macro avg       0.50      0.50      0.50    129668\n",
      "weighted avg       0.99      0.99      0.99    129668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train data set\n",
    "a = LocalOutlierFactor(n_neighbors = 20,contamination = outlier_fraction)\n",
    "y_prediction1 = a.fit_predict(df_Train) # Fitting the model.\n",
    "y_prediction1[y_prediction1 == 1] = 0 # Valid transactions are labelled as 0.\n",
    "y_prediction1[y_prediction1 == -1] = 1 # Fraudulent transactions are labelled as 1.\n",
    "errors1 = (y_prediction1 != Y_train).sum() # Total number of errors is calculated.\n",
    "print(errors1)\n",
    "print(accuracy_score(y_prediction1,Y_train))\n",
    "print(classification_report(y_prediction1,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "0.9899589721442453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     27635\n",
      "           1       0.01      0.01      0.01       151\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.50      0.50      0.50     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test data set\n",
    "\n",
    "y_prediction1 = a.fit_predict(df_Test) # Fitting the model.\n",
    "y_prediction1[y_prediction1 == 1] = 0 # Valid transactions are labelled as 0.\n",
    "y_prediction1[y_prediction1 == -1] = 1 # Fraudulent transactions are labelled as 1.\n",
    "errors1 = (y_prediction1 != Y_test).sum() # Total number of errors is calculated.\n",
    "print(errors1)\n",
    "print(accuracy_score(y_prediction1,Y_test))\n",
    "print(classification_report(y_prediction1,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that Local Outlier Factor does not perform well as it gives Recall of 0.01 for bothe Test set and Train set.  \n",
    "## -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Isolation Forest    \n",
    "Isolation Forest is based on the Decision Tree algorithm. It isolates the outliers by randomly selecting a feature from the given set of features and then randomly selecting a split value between the max and min values of that feature. This random partitioning of features will produce shorter paths in trees for the anomalous data points, thus distinguishing them from the rest of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgement\n",
    "https://medium.com/datadriveninvestor/credit-card-fraud-detection-using-local-outlier-factor-and-isolation-forest-in-python-56edd0a44af5\n",
    "    \n",
    "\n",
    "#### https://www.youtube.com/watch?v=TP3wdwD8JVY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376\n",
      "0.989388283925101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    128967\n",
      "           1       0.02      0.02      0.02       701\n",
      "\n",
      "    accuracy                           0.99    129668\n",
      "   macro avg       0.51      0.51      0.51    129668\n",
      "weighted avg       0.99      0.99      0.99    129668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isolation forest for train\n",
    "b = IsolationForest(max_samples = len(df_Train),contamination = outlier_fraction).fit(df_Train) # Fitting the model.\n",
    "y_prediction2 = b.predict(df_Train) # Prediction using trained model.\n",
    "y_prediction2[y_prediction2 == 1] = 0 # Valid transactions are labelled as 0.\n",
    "y_prediction2[y_prediction2 == -1] = 1 # Fraudulent transactions are labelled as 1.\n",
    "errors2 = (y_prediction2 != Y_train).sum() # Total number of errors is calculated.\n",
    "print(errors2)\n",
    "print(accuracy_score(y_prediction2,Y_train))\n",
    "print(classification_report(y_prediction2,Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n",
      "0.9902468869214712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     27635\n",
      "           1       0.04      0.03      0.04       151\n",
      "\n",
      "    accuracy                           0.99     27786\n",
      "   macro avg       0.52      0.51      0.52     27786\n",
      "weighted avg       0.99      0.99      0.99     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isolation forest for train\n",
    "b = IsolationForest(max_samples = len(df_Test),contamination = outlier_fraction).fit(df_Test) # Fitting the model.\n",
    "y_prediction2 = b.predict(df_Test) # Prediction using trained model.\n",
    "y_prediction2[y_prediction2 == 1] = 0 # Valid transactions are labelled as 0.\n",
    "y_prediction2[y_prediction2 == -1] = 1 # Fraudulent transactions are labelled as 1.\n",
    "errors2 = (y_prediction2 != Y_test).sum() # Total number of errors is calculated.\n",
    "print(errors2)\n",
    "print(accuracy_score(y_prediction2,Y_test))\n",
    "print(classification_report(y_prediction2,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that Isolation Forest does not perform well as it gives Recall of 0.03 on Test set and 0.02 on Train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Implementing Autoencoder to detect the fraud cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acknowledgemet:\n",
    "https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd (Venelin Vankov)    \n",
    "https://github.com/curiousily/Credit-Card-Fraud-Detection-using-Autoencoders-in-Keras/blob/master/fraud_detection.ipynb    \n",
    "\n",
    "https://www.youtube.com/watch?v=S31E-ftRfQI    \n",
    "\n",
    "https://github.com/dpanagop/ML_and_AI_examples/blob/master/Credit_Fraud_detection_with_autoencoders.ipynb  (not used)   \n",
    "https://www.youtube.com/watch?v=S31E-ftRfQI  (refernce)  \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "\n",
    "\n",
    "df_Train_copy = df_Train_copy.drop(['unix_time'], axis=1)\n",
    "df_Test_copy = df_Test_copy.drop(['unix_time'], axis=1)\n",
    "\n",
    "df_Train_copy['amt'] = StandardScaler().fit_transform(df_Train_copy['amt'].values.reshape(-1, 1))\n",
    "df_Test_copy['amt'] = StandardScaler().fit_transform(df_Test_copy['amt'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129668, 3076), (27786, 3076))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train_copy.shape,df_Test_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Autoencoder uses 4 fully connected layers with 14, 7, 7 and 29 neurons respectively. The first two layers are used for our encoder, the last two go for the decoder. Additionally, L1 regularization will be used during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "input_dim = df_Train_copy.shape[1]\n",
    "\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   2/4053 [..............................] - ETA: 6:12 - loss: 13892927.0000 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_end` time: 0.1719s). Check your callbacks.\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33123092.0000 - accuracy: 0.7762 - val_loss: 35099472.0000 - val_accuracy: 0.7910\n",
      "Epoch 2/100\n",
      "4053/4053 [==============================] - 9s 2ms/step - loss: 33120408.0000 - accuracy: 0.7910 - val_loss: 35096760.0000 - val_accuracy: 0.7910\n",
      "Epoch 3/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33117814.0000 - accuracy: 0.7910 - val_loss: 35094080.0000 - val_accuracy: 0.7910\n",
      "Epoch 4/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33115254.0000 - accuracy: 0.7910 - val_loss: 35091440.0000 - val_accuracy: 0.7910\n",
      "Epoch 5/100\n",
      "4053/4053 [==============================] - 10s 3ms/step - loss: 33112558.0000 - accuracy: 0.7910 - val_loss: 35088764.0000 - val_accuracy: 0.7910\n",
      "Epoch 6/100\n",
      "4053/4053 [==============================] - 10s 3ms/step - loss: 33109974.0000 - accuracy: 0.7910 - val_loss: 35086112.0000 - val_accuracy: 0.7910\n",
      "Epoch 7/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33107394.0000 - accuracy: 0.7910 - val_loss: 35083460.0000 - val_accuracy: 0.7910\n",
      "Epoch 8/100\n",
      "4053/4053 [==============================] - 10s 3ms/step - loss: 33104734.0000 - accuracy: 0.7910 - val_loss: 35080796.0000 - val_accuracy: 0.7910\n",
      "Epoch 9/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33102136.0000 - accuracy: 0.7910 - val_loss: 35078120.0000 - val_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "4053/4053 [==============================] - 10s 3ms/step - loss: 33099518.0000 - accuracy: 0.7910 - val_loss: 35075476.0000 - val_accuracy: 0.7910\n",
      "Epoch 11/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33096904.0000 - accuracy: 0.7910 - val_loss: 35072852.0000 - val_accuracy: 0.7910\n",
      "Epoch 12/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33094256.0000 - accuracy: 0.7910 - val_loss: 35070168.0000 - val_accuracy: 0.7910\n",
      "Epoch 13/100\n",
      "4053/4053 [==============================] - 10s 2ms/step - loss: 33091690.0000 - accuracy: 0.7910 - val_loss: 35067488.0000 - val_accuracy: 0.7910\n",
      "Epoch 14/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33089034.0000 - accuracy: 0.7910 - val_loss: 35064868.0000 - val_accuracy: 0.7910\n",
      "Epoch 15/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33086462.0000 - accuracy: 0.7910 - val_loss: 35062176.0000 - val_accuracy: 0.7910\n",
      "Epoch 16/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33083900.0000 - accuracy: 0.7910 - val_loss: 35059508.0000 - val_accuracy: 0.7910\n",
      "Epoch 17/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33081174.0000 - accuracy: 0.7910 - val_loss: 35056876.0000 - val_accuracy: 0.7910\n",
      "Epoch 18/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 33078646.0000 - accuracy: 0.7910 - val_loss: 35054244.0000 - val_accuracy: 0.7910\n",
      "Epoch 19/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 33076054.0000 - accuracy: 0.7910 - val_loss: 35051572.0000 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33073454.0000 - accuracy: 0.7910 - val_loss: 35048964.0000 - val_accuracy: 0.7910\n",
      "Epoch 21/100\n",
      "4053/4053 [==============================] - 11s 3ms/step - loss: 33070896.0000 - accuracy: 0.7910 - val_loss: 35046320.0000 - val_accuracy: 0.7910\n",
      "Epoch 22/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 33068320.0000 - accuracy: 0.7910 - val_loss: 35043704.0000 - val_accuracy: 0.7910\n",
      "Epoch 23/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 33065704.0000 - accuracy: 0.7910 - val_loss: 35041036.0000 - val_accuracy: 0.7910\n",
      "Epoch 24/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 33063120.0000 - accuracy: 0.7910 - val_loss: 35038392.0000 - val_accuracy: 0.7910\n",
      "Epoch 25/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33060492.0000 - accuracy: 0.7910 - val_loss: 35035776.0000 - val_accuracy: 0.7910\n",
      "Epoch 26/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33057874.0000 - accuracy: 0.7910 - val_loss: 35033132.0000 - val_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 33055332.0000 - accuracy: 0.7910 - val_loss: 35030480.0000 - val_accuracy: 0.7910\n",
      "Epoch 28/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33052686.0000 - accuracy: 0.7910 - val_loss: 35027868.0000 - val_accuracy: 0.7910\n",
      "Epoch 29/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33050130.0000 - accuracy: 0.7910 - val_loss: 35025232.0000 - val_accuracy: 0.7910\n",
      "Epoch 30/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33047560.0000 - accuracy: 0.7910 - val_loss: 35022608.0000 - val_accuracy: 0.7910\n",
      "Epoch 31/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33044990.0000 - accuracy: 0.7910 - val_loss: 35019964.0000 - val_accuracy: 0.7910\n",
      "Epoch 32/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33042428.0000 - accuracy: 0.7910 - val_loss: 35017360.0000 - val_accuracy: 0.7910\n",
      "Epoch 33/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33039808.0000 - accuracy: 0.7910 - val_loss: 35014732.0000 - val_accuracy: 0.7910\n",
      "Epoch 34/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33037226.0000 - accuracy: 0.7910 - val_loss: 35012104.0000 - val_accuracy: 0.7910\n",
      "Epoch 35/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33034606.0000 - accuracy: 0.7910 - val_loss: 35009472.0000 - val_accuracy: 0.7910\n",
      "Epoch 36/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33032102.0000 - accuracy: 0.7910 - val_loss: 35006856.0000 - val_accuracy: 0.7910\n",
      "Epoch 37/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33029504.0000 - accuracy: 0.7910 - val_loss: 35004228.0000 - val_accuracy: 0.7910\n",
      "Epoch 38/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33026904.0000 - accuracy: 0.7910 - val_loss: 35001604.0000 - val_accuracy: 0.7910\n",
      "Epoch 39/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33024348.0000 - accuracy: 0.7910 - val_loss: 34998976.0000 - val_accuracy: 0.7910\n",
      "Epoch 40/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33021762.0000 - accuracy: 0.7910 - val_loss: 34996388.0000 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 33019288.0000 - accuracy: 0.7910 - val_loss: 34993744.0000 - val_accuracy: 0.7910\n",
      "Epoch 42/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 33016634.0000 - accuracy: 0.7910 - val_loss: 34991168.0000 - val_accuracy: 0.7910\n",
      "Epoch 43/100\n",
      "4053/4053 [==============================] - 16s 4ms/step - loss: 33014120.0000 - accuracy: 0.7910 - val_loss: 34988552.0000 - val_accuracy: 0.7910\n",
      "Epoch 44/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 33011514.0000 - accuracy: 0.7910 - val_loss: 34985928.0000 - val_accuracy: 0.7910\n",
      "Epoch 45/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33008994.0000 - accuracy: 0.7910 - val_loss: 34983324.0000 - val_accuracy: 0.7910\n",
      "Epoch 46/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 33006392.0000 - accuracy: 0.7910 - val_loss: 34980692.0000 - val_accuracy: 0.7910\n",
      "Epoch 47/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 33003804.0000 - accuracy: 0.7910 - val_loss: 34978092.0000 - val_accuracy: 0.7910\n",
      "Epoch 48/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 33001288.0000 - accuracy: 0.7910 - val_loss: 34975456.0000 - val_accuracy: 0.7910\n",
      "Epoch 49/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32998662.0000 - accuracy: 0.7910 - val_loss: 34972864.0000 - val_accuracy: 0.7910\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32996124.0000 - accuracy: 0.7910 - val_loss: 34970228.0000 - val_accuracy: 0.7910\n",
      "Epoch 51/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32993570.0000 - accuracy: 0.7910 - val_loss: 34967676.0000 - val_accuracy: 0.7910\n",
      "Epoch 52/100\n",
      "4053/4053 [==============================] - 16s 4ms/step - loss: 32991026.0000 - accuracy: 0.7910 - val_loss: 34965048.0000 - val_accuracy: 0.7910\n",
      "Epoch 53/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32988432.0000 - accuracy: 0.7910 - val_loss: 34962480.0000 - val_accuracy: 0.7910\n",
      "Epoch 54/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32985950.0000 - accuracy: 0.7910 - val_loss: 34959868.0000 - val_accuracy: 0.7910\n",
      "Epoch 55/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32983384.0000 - accuracy: 0.7910 - val_loss: 34957276.0000 - val_accuracy: 0.7910\n",
      "Epoch 56/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32980792.0000 - accuracy: 0.7910 - val_loss: 34954660.0000 - val_accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32978308.0000 - accuracy: 0.7910 - val_loss: 34952080.0000 - val_accuracy: 0.7910\n",
      "Epoch 58/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 32975704.0000 - accuracy: 0.7910 - val_loss: 34949488.0000 - val_accuracy: 0.7910\n",
      "Epoch 59/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32973192.0000 - accuracy: 0.7910 - val_loss: 34946888.0000 - val_accuracy: 0.7910\n",
      "Epoch 60/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32970622.0000 - accuracy: 0.7910 - val_loss: 34944276.0000 - val_accuracy: 0.7910\n",
      "Epoch 61/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 32968054.0000 - accuracy: 0.7910 - val_loss: 34941696.0000 - val_accuracy: 0.7910\n",
      "Epoch 62/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32965546.0000 - accuracy: 0.7910 - val_loss: 34939084.0000 - val_accuracy: 0.7910\n",
      "Epoch 63/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32962960.0000 - accuracy: 0.7910 - val_loss: 34936532.0000 - val_accuracy: 0.7910\n",
      "Epoch 64/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32960398.0000 - accuracy: 0.7910 - val_loss: 34933948.0000 - val_accuracy: 0.7910\n",
      "Epoch 65/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 32957924.0000 - accuracy: 0.7910 - val_loss: 34931364.0000 - val_accuracy: 0.7910\n",
      "Epoch 66/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32955360.0000 - accuracy: 0.7910 - val_loss: 34928776.0000 - val_accuracy: 0.7910\n",
      "Epoch 67/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 32952852.0000 - accuracy: 0.7910 - val_loss: 34926212.0000 - val_accuracy: 0.7910\n",
      "Epoch 68/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32950234.0000 - accuracy: 0.7910 - val_loss: 34923636.0000 - val_accuracy: 0.7910\n",
      "Epoch 69/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32947806.0000 - accuracy: 0.7910 - val_loss: 34921044.0000 - val_accuracy: 0.7910\n",
      "Epoch 70/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32945264.0000 - accuracy: 0.7910 - val_loss: 34918464.0000 - val_accuracy: 0.7910\n",
      "Epoch 71/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32942708.0000 - accuracy: 0.7910 - val_loss: 34915888.0000 - val_accuracy: 0.7910\n",
      "Epoch 72/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32940198.0000 - accuracy: 0.7910 - val_loss: 34913324.0000 - val_accuracy: 0.7910\n",
      "Epoch 73/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32937666.0000 - accuracy: 0.7910 - val_loss: 34910732.0000 - val_accuracy: 0.7910\n",
      "Epoch 74/100\n",
      "4053/4053 [==============================] - 16s 4ms/step - loss: 32935156.0000 - accuracy: 0.7910 - val_loss: 34908184.0000 - val_accuracy: 0.7910\n",
      "Epoch 75/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32932644.0000 - accuracy: 0.7910 - val_loss: 34905612.0000 - val_accuracy: 0.7910\n",
      "Epoch 76/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32930102.0000 - accuracy: 0.7910 - val_loss: 34903052.0000 - val_accuracy: 0.7910\n",
      "Epoch 77/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32927606.0000 - accuracy: 0.7910 - val_loss: 34900452.0000 - val_accuracy: 0.7910\n",
      "Epoch 78/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32925066.0000 - accuracy: 0.7910 - val_loss: 34897916.0000 - val_accuracy: 0.7910\n",
      "Epoch 79/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32922538.0000 - accuracy: 0.7910 - val_loss: 34895352.0000 - val_accuracy: 0.7910\n",
      "Epoch 80/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32920038.0000 - accuracy: 0.7910 - val_loss: 34892768.0000 - val_accuracy: 0.7910\n",
      "Epoch 81/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32917460.0000 - accuracy: 0.7910 - val_loss: 34890212.0000 - val_accuracy: 0.7910\n",
      "Epoch 82/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32914974.0000 - accuracy: 0.7910 - val_loss: 34887640.0000 - val_accuracy: 0.7910\n",
      "Epoch 83/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32912492.0000 - accuracy: 0.7910 - val_loss: 34885084.0000 - val_accuracy: 0.7910\n",
      "Epoch 84/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 32909982.0000 - accuracy: 0.7910 - val_loss: 34882540.0000 - val_accuracy: 0.7910\n",
      "Epoch 85/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 32907412.0000 - accuracy: 0.7910 - val_loss: 34879988.0000 - val_accuracy: 0.7910\n",
      "Epoch 86/100\n",
      "4053/4053 [==============================] - 14s 4ms/step - loss: 32904864.0000 - accuracy: 0.7910 - val_loss: 34877436.0000 - val_accuracy: 0.7910\n",
      "Epoch 87/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32902430.0000 - accuracy: 0.7910 - val_loss: 34874860.0000 - val_accuracy: 0.7910\n",
      "Epoch 88/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 32899918.0000 - accuracy: 0.7910 - val_loss: 34872308.0000 - val_accuracy: 0.7910\n",
      "Epoch 89/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32897422.0000 - accuracy: 0.7910 - val_loss: 34869752.0000 - val_accuracy: 0.7910\n",
      "Epoch 90/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32894842.0000 - accuracy: 0.7910 - val_loss: 34867224.0000 - val_accuracy: 0.7910\n",
      "Epoch 91/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32892420.0000 - accuracy: 0.7910 - val_loss: 34864656.0000 - val_accuracy: 0.7910\n",
      "Epoch 92/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32889864.0000 - accuracy: 0.7910 - val_loss: 34862132.0000 - val_accuracy: 0.7910\n",
      "Epoch 93/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32887428.0000 - accuracy: 0.7910 - val_loss: 34859600.0000 - val_accuracy: 0.7910\n",
      "Epoch 94/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 32884914.0000 - accuracy: 0.7910 - val_loss: 34856996.0000 - val_accuracy: 0.7910\n",
      "Epoch 95/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32882412.0000 - accuracy: 0.7910 - val_loss: 34854476.0000 - val_accuracy: 0.7910\n",
      "Epoch 96/100\n",
      "4053/4053 [==============================] - 16s 4ms/step - loss: 32879940.0000 - accuracy: 0.7910 - val_loss: 34851920.0000 - val_accuracy: 0.7910\n",
      "Epoch 97/100\n",
      "4053/4053 [==============================] - 15s 4ms/step - loss: 32877382.0000 - accuracy: 0.7910 - val_loss: 34849392.0000 - val_accuracy: 0.7910\n",
      "Epoch 98/100\n",
      "4053/4053 [==============================] - 13s 3ms/step - loss: 32874878.0000 - accuracy: 0.7910 - val_loss: 34846848.0000 - val_accuracy: 0.7910\n",
      "Epoch 99/100\n",
      "4053/4053 [==============================] - 12s 3ms/step - loss: 32872370.0000 - accuracy: 0.7910 - val_loss: 34844292.0000 - val_accuracy: 0.7910\n",
      "Epoch 100/100\n",
      "4053/4053 [==============================] - 14s 3ms/step - loss: 32869920.0000 - accuracy: 0.7910 - val_loss: 34841736.0000 - val_accuracy: 0.7910\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath=\"model.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "history = autoencoder.fit(df_Train_copy, df_Train_copy,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(df_Test_copy, df_Test_copy),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, tensorboard]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved model\n",
    "autoencoder = load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjqklEQVR4nO3de5hddX3v8fdnZvbccpvJBSQJkKhgwZwadOSgiA+CKBcLtLRIlR5rPY0+0kpb9CinoA/Uttr2QY4VRRSO9AJIQWrKxQI2SDnKZQJRw82AhibcEjIzSeaWmcx8zx9r7Zk1O2uSPcnsTLLn83qe/ey1123/VvZkPvO7rN9WRGBmZlaqZqoLYGZmByYHhJmZ5XJAmJlZLgeEmZnlckCYmVkuB4SZmeVyQJjtI0nfkfTFMvddL+m9+3oes/3BAWFmZrkcEGZmlssBYdNC2rTzGUk/k9Qj6XpJh0q6R9J2SfdLas3sf7akJyV1SXpA0jGZbcdJejw97rtAY8l7fUDSmvTYH0v69b0s8x9Kek5Sh6SVkham6yXpK5I2Sdom6eeSlqXbzpT0VFq2FyV9eq/+wcxwQNj0ch5wGnA08BvAPcD/BhaQ/F/4FICko4GbgT9Jt90N/Jukekn1wL8C/wjMBf4lPS/psccBNwAfB+YB3wRWSmqYSEElnQL8NXA+cBjwAnBLuvl9wLvT65iT7rMl3XY98PGImAUsA/5jIu9rllVVASHphvSvqrVl7PuV9K+8NZJ+IalrPxTRptbfR8SrEfEi8J/AIxHxRET0A3cAx6X7fRC4KyLui4hB4O+AJuCdwAlAAbg6IgYj4jbgscx7rAC+GRGPRMRQRNwI7EiPm4gPAzdExOMRsQO4FHiHpCXAIDAL+DVAEfF0RLycHjcIHCtpdkR0RsTjE3xfsxFVFRDAd4DTy9kxIv40IpZHxHLg74HvVbBcdmB4NbPcl/N6Zrq8kOQvdgAiYhjYACxKt70YY2e5fCGzfCRwSdq81JX+4XF4etxElJahm6SWsCgi/gP4GnANsEnSdZJmp7ueB5wJvCDpR5LeMcH3NRtRVQEREQ8CHdl1kt4g6QeSVkv6T0m/lnPo75I0KZgBvETyix5I2vxJfsm/CLwMLErXFR2RWd4A/GVEtGQezREx0Z+v0jLMIGmyehEgIr4aEW8DjiVpavpMuv6xiDgHOISkKezWCb6v2YiqCohxXAf8cfqf6dPA17MbJR0JLMVttTbqVuAsSadKKgCXkDQT/Rj4CbAT+JSkgqTfAo7PHPst4BOS/nvamTxD0lmSZk2wDDcDH5W0PO2/+CuSJrH1kt6enr8A9AD9wHDaR/JhSXPSprFtwPA+/DvYNFfVASFpJkm78b9IWkPSYXhYyW4XALdFxNB+Lp4doCLiWeBCkqbH10g6tH8jIgYiYgD4LeD3SWqrHyTTPBkR7cAfkjQBdQLPpftOtAz3A5cDt5PUWt5A8rMKMJskiDpJmqG2AH+bbvs9YL2kbcAnSPoyzPaKqu0Lg9JOvDsjYlnaLvtsRJSGQnb/J4CLIuLH+6uMZmYHg6quQUTENuBXkn4HRsaPv6W4Pe2PaCVpNjAzs4yqCghJN5P8sn+TpI2SPkZSxf6YpJ8CTwLnZA65ALglqq0aZWY2CaquicnMzCZHVdUgzMxs8tRNdQEmy/z582PJkiVTXQwzs4PK6tWrX4uIBXnbqiYglixZQnt7+1QXw8zsoCLphfG2uYnJzMxyOSDMzCyXA8LMzHJVTR+EmdneGBwcZOPGjfT39091USqqsbGRxYsXUygUyj7GAWFm09rGjRuZNWsWS5YsYewkvdUjItiyZQsbN25k6dKlZR/nJiYzm9b6+/uZN29e1YYDgCTmzZs34VqSA8LMpr1qDoeivblGNzFtfwUe/RbMmA/N86B5LjTNHV2unwnT4IfHzKyUA2LrRnjoKohxvleltn5sYIx5npfZ1jr6umGWQ8XMytLV1cVNN93EJz/5yQkdd+aZZ3LTTTfR0tJSmYLhgIDFbXD5Fujvgt4O6N0Cfelzz2vpcvro64BNTyXr+7vGD5WawmiAlIZKNmya5qbr50LDbIeK2TTU1dXF17/+9V0CYufOndTVjf8r+u6776500RwQANTUjP6i5o3lHTM8PBoqxUDp3TIaMsXlvg7Y9HQaPJ0w3hfX1dRlQmUeNLXmhEo2dBwqZtXgc5/7HM8//zzLly+nUCjQ2NhIa2srzzzzDL/4xS8499xz2bBhA/39/Vx88cWsWLECGJ1eqLu7mzPOOIN3vetd/PjHP2bRokV8//vfp6mpaZ/L5oDYW2NCpUzDw7Bj69gayUgtJRswHbD52dHay7ihUkiDJBMaI7WSbNgUt7VCY0tSdjPbxRX/9iRPvbRtUs957MLZfOE33jzu9i996UusXbuWNWvW8MADD3DWWWexdu3akeGoN9xwA3PnzqWvr4+3v/3tnHfeecybN2/MOdatW8fNN9/Mt771Lc4//3xuv/12Lrzwwn0uuwNif6qpSX5JN7XCvDeUd0wE9G8dDYu8QClue+250W3DO/PPp5rRUMnrP8lrDmtqgZraSftnMLPxHX/88WPuVfjqV7/KHXfcAcCGDRtYt27dLgGxdOlSli9fDsDb3vY21q9fPyllcUAc6KTkF3RTC8x9fXnHRMCO7fkhUhounevhpceT10MD4xUiLcPcXZu5sjWWMcutUFv+HZtmB4Ld/aW/v8yYMWNk+YEHHuD+++/nJz/5Cc3NzZx88sm59zI0NDSMLNfW1tLX1zcpZalYQEhqBB4EGtL3uS0ivlCyz+8Dfwu8mK76WkR8O932EeCydP0XI+LGSpW16kjQODt5zC3zrskIGOgZDY++DujtHNtpXwyVbRvhlZ8lr3fu5sabhjnj1E4ywVIaMIXGyfk3MDtIzJo1i+3bt+du27p1K62trTQ3N/PMM8/w8MMP79eyVbIGsQM4JSK6JRWAhyTdExGlV/jdiPij7ApJc4EvAG1AAKslrYyIzgqWd3qToGFm8mg9svzjBnozIdIxdtRXdn3va/DaL5Llgfz/DAAUmjOd9KXNXXN33dY0F+pnuLPeDlrz5s3jxBNPZNmyZTQ1NXHooYeObDv99NO59tprOeaYY3jTm97ECSecsF/LVrGAiOTLrrvTl4X0Ue4XYL8fuC8iOgAk3QecDtw82eW0fVTfnDxaDi//mJ07khFdY5q/isudY2srXS8ky/1bxz9fbcOuw4bHdM7n1F4aZruz3g4YN910U+76hoYG7rnnntxtxX6G+fPns3bt2pH1n/70pyetXBXtg5BUC6wmGTt6TUQ8krPbeZLeDfwC+NOI2AAsAjZk9tmYris9/wpgBcARRxwxyaW3iqlrgFmvSx7lGtqZDisuDZXs686cYcXj3Kui2pJ+ld0ETHG5qRVq3W1n00dFf9ojYghYLqkFuEPSsohYm9nl34CbI2KHpI8DNwKnTOD81wHXAbS1tZVbO7GDUW1dMh3KjPnlH5MdVlxaM+nrzDR/bYGu/4KX1qSd9TvGP2fjnJyO+XQkWF6Nxf0qdhDbL38ORUSXpFUkzURrM+u3ZHb7NvA36fKLwMmZbYuBBypbSqs62WHF5Sp21u+pT6WvA7o3waZnkvWDPeOfs9CchkZrfo0lW3MpLvsmSDsAVHIU0wJgMA2HJuA04Msl+xwWES+nL88Gnk6X/x34K0nF/9nvAy6tVFnNRmQ761sm0Gy5c8fYmkq2dtLXOTZsiiPA+roYt1uupi4Nt2ygtOYESyZs3ARmk6ySP02HATem/RA1wK0RcaekK4H2iFgJfErS2cBOoAP4fYCI6JD0F8Bj6bmuLHZYmx2Q6hpg9mHJo1zDQ0nn+y73qZSOAOuALc+PNouNe78K6dDi8YYS56xrmpsMMjDLUclRTD8DjstZ//nM8qWMUzOIiBuAGypVPrMpV1M78elaSpvA8mooxXDp2QyvPZt03u9uaHFd49jpWMYLkuyzp2yZFlwfNTuY7HUT2MCutZQxz5lO+01PjzaXjTcPGNpNmOwmZNxhv4u9ne4b4Oqrr2bFihU0N1emFuiAMJsO6uonPrR4eBh2bNs1QPKawba9CK+sTV4P9o5/zl067McJkpGQqf4JJseb7rscV199NRdeeKEDwsz2s5qazDxgEzhusH83tZXSDvufJ8+7+36V4gST4wXIeOFS2PfprveH7HTfp512Gocccgi33norO3bs4Dd/8ze54oor6Onp4fzzz2fjxo0MDQ1x+eWX8+qrr/LSSy/xnve8h/nz57Nq1apJL5sDwswmV6ERCgth9sLyjyl+v8pIgJTWWDI3RG7bmATLnmordU05nfM5NZedhyZziqkO7v3zpCY0mV733+CML427OTvd97333sttt93Go48+SkRw9tln8+CDD7J582YWLlzIXXfdBSRzNM2ZM4errrqKVatWMX/+BO4PmgAHhJlNvez3q5Q7FT6MU1vp3LXG0rslDZXOXe+wf/+tsCkdbtyzGQa603tQlPPM2Ncjy+n6fXTvvfdy7733ctxxyfie7u5u1q1bx0knncQll1zCZz/7WT7wgQ9w0kkn7fN7lcMBYWYHr72trWTvsO+ogZYjk+9Qed9fJs/DQ8lzZJfHaQIDQMm9KzW1Jc/pcs+W/G0lN0NGBJdeeikf//jHd3mHxx9/nLvvvpvLLruMU089lc9//vO77DPZHBBmNr2U3mG//enyhhrH8GhYZENkeGhskAzvTG6cHO5J1u1ujlLVMqtvO9u3dsKW53j/O9/C5X/9FT589qnMnDWHF195lUJ9EzuHg7nzF3Dhhy6gZc4cvn399cDoVOFuYjIzm0qqgdqaiX0RVkQaLDt3DZc0VOY1zubE49/KsnedyRnvOZEPnfM+3nHKGQDMbG7in/7+izy3fgOf+eLV1KiGQqGOb3zpctj0FCs+dC6nn3YqCxcexqoH/9/kX3IyK/fBr62tLdrb26e6GGZ2kHn66ac55phjproYY0WUNHXl1VyKy0PJfTFzFu/xtHnXKml1RLTl7e8ahJnZgUZKaipT/LW91Xv3iZmZ7RMHhJlNe9XS1L47e3ONDggzm9YaGxvZsmVLVYdERLBlyxYaGyc2F5b7IMxsWlu8eDEbN25k8+bNU12UimpsbGTx4j13ZGc5IMxsWisUCixdunSqi3FAchOTmZnlckCYmVkuB4SZmeVyQJiZWS4HhJmZ5XJAmJlZLgeEmZnlckCYmVkuB4SZmeVyQJiZWS4HhJmZ5XJAmJlZLgeEmZnlckCYmVkuB4SZmeVyQJiZWS4HhJmZ5XJAmJlZLgeEmZnlckCYmVmuigWEpEZJj0r6qaQnJV2xm33PkxSS2tLXSyT1SVqTPq6tVDnNzCxfXQXPvQM4JSK6JRWAhyTdExEPZ3eSNAu4GHik5PjnI2J5BctnZma7UbEaRCS605eF9BE5u/4F8GWgv1JlMTOziatoH4SkWklrgE3AfRHxSMn2twKHR8RdOYcvlfSEpB9JOmmc86+Q1C6pffPmzZNefjOz6ayiARERQ2kz0WLgeEnLitsk1QBXAZfkHPoycEREHAf8GXCTpNk5578uItoiom3BggUVuQYzs+lqv4xiioguYBVwemb1LGAZ8ICk9cAJwEpJbRGxIyK2pMeuBp4Hjt4fZTUzs0QlRzEtkNSSLjcBpwHPFLdHxNaImB8RSyJiCfAwcHZEtKfH1qbHvh44CvhlpcpqZma7quQopsOAG9Nf9DXArRFxp6QrgfaIWLmbY98NXClpEBgGPhERHRUsq5mZlVBE3sCig09bW1u0t7dPdTHMzA4qklZHRFveNt9JbWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZparrICQdLGk2UpcL+lxSe+rdOHMzGzqlFuD+IOI2Aa8D2gFfg/4UsVKZWZmU67cgFD6fCbwjxHxZGZd/gFSo6RHJf1U0pOSrtjNvudJCkltmXWXSnpO0rOS3l9mOc3MbJLUlbnfakn3AkuBSyXNAob3cMwO4JSI6JZUAB6SdE9EPJzdKT3XxcAjmXXHAhcAbwYWAvdLOjoihsosr5mZ7aNyaxAfAz4HvD0ieoEC8NHdHRCJ7vRlIX1Ezq5/AXwZ6M+sOwe4JSJ2RMSvgOeA48ssq5mZTYJyA+IdwLMR0SXpQuAyYOueDpJUK2kNsAm4LyIeKdn+VuDwiLir5NBFwIbM643putLzr5DULql98+bNZV6KmZmVo9yA+AbQK+ktwCXA88A/7OmgiBiKiOXAYuB4ScuK2yTVAFel59srEXFdRLRFRNuCBQv29jRmZpaj3IDYGRFB0vTztYi4BphV7ptERBewCjg9s3oWsAx4QNJ64ARgZdpR/SJweGbfxek6MzPbT8oNiO2SLiUZ3npX+td/YXcHSFogqSVdbgJOA54pbo+IrRExPyKWRMQS4GHg7IhoB1YCF0hqkLQUOAp4dGKXZmZm+6LcgPggyaikP4iIV0j+ov/bPRxzGLBK0s+Ax0j6IO6UdKWks3d3YDqM9lbgKeAHwEUewWRmtn8paTkqY0fpUODt6ctHI2JTxUq1F9ra2qK9vX2qi2FmdlCRtDoi2vK2lTvVxvkkTTy/A5wPPCLptyeviGZmdqAp90a5Pye5B2ITJP0LwP3AbZUqmJmZTa1y+yBqSpqUtkzgWDMzOwiVW4P4gaR/B25OX38QuLsyRTIzswNBWQEREZ+RdB5wYrrquoi4o3LFMjOzqVZuDYKIuB24vYJlMTOzA8huA0LSdvIn2BPJfHyzK1IqMzObcrsNiIgoezoNMzOrLh6JZGZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGZmlssBYWZmuRwQZmaWywFhZma5KhYQkholPSrpp5KelHRFzj6fkPRzSWskPSTp2HT9Ekl96fo1kq6tVDnNzCxfXQXPvQM4JSK6JRWAhyTdExEPZ/a5KSKuBZB0NnAVcHq67fmIWF7B8pmZ2W5ULCAiIoDu9GUhfUTJPtsyL2eUbjczs6lT0T4ISbWS1gCbgPsi4pGcfS6S9DzwN8CnMpuWSnpC0o8knTTO+VdIapfUvnnz5kpcgpnZtKXkD/0Kv4nUAtwB/HFErB1nnw8B74+Ij0hqAGZGxBZJbwP+FXhzSY1jjLa2tmhvb5/8wpuZVTFJqyOiLW/bfhnFFBFdwCpG+xfy3AKcm+6/IyK2pMurgeeBoytbSjMzy6rkKKYFac0BSU3AacAzJfsclXl5FrAuc2xtuvx64Cjgl5Uqq5mZ7aqSo5gOA25Mf9HXALdGxJ2SrgTaI2Il8EeS3gsMAp3AR9Jj3w1cKWkQGAY+EREdFSyrmZmV2C99EPuD+yDMzCZuyvsgzMzs4OOAMDOzXA4IMzPL5YAwM7NcDggzM8vlgDAzs1wOCDMzy+WAMDOzXA4IMzPL5YAwM7NcDggzM8vlgDAzs1wOCDMzy+WAMDOzXA4IMzPL5YAwM7NcDggzM8vlgDAzs1wOCDMzy+WAMDOzXA4IMzPL5YAwM7NcDggzM8vlgDAzs1wOCDMzy+WAMDOzXHVTXYCptr1/kPb1nbTOqGducz2tMwrMbKhD0lQXzcxsSk37gHhuUzcf/c5jY9YVasWcpnpamwu0NtfTkj63zqhn7owCLc2jYdLSXE9rcz1zmgrU1jhUzKx6TPuAOPrQWXzvk++ks2eAzt5BOnp20Nk7SFfvAJ09g3T2DvDCll7WbOiis3eAwaHIPY8EsxsLSaiktZGW5tFAaW1OAidZN7pcX+dWPjM7ME37gJjRUMdbj2gta9+IoGdgiI7uATp7k0dX72C6nIZK+vzKtn6efnkbnb2D9A0Ojf/+9bW0zqgfqaFkay1zZ9SP1FZa0uBpaSrQXF/rJjAzq7hpHxATIYmZDXXMbKjjiHnNZR/XPzg0GiQ9A3QUgyRdzm5b/1oPnb0DbO/fOe756mtrMs1eSZDMnVFPS1P9mPXZmsvsxgI1bgIzswlwQOwHjYVaXjenltfNaSz7mMGhYbrS2khHT0kNpW+Arp7BkVrMs69sp6NngK19gwznt4BRI5jTVBhTU2lpzj5nlmeM1mIa6mon6V/BzA42DogDVKG2hgWzGlgwq6HsY4aHg+39O3fT/JUsd/YM8GJXP0++tI3O3gH6B4fHPeeM+tqRfpNis1e2436kxpIJFjeBmVUHB0QVqakRc5oLzGkusIQZZR/XPziUNnGN1lKSgBmgI11XbBb7r45eOnrKbwJraS5klvM67Qsjo8Dqat1hb3YgcUAYjYVaDpvTxGFzmso+ZufQMF19mUDpSWosHcXaS8/gSC3mV6/18HhvF127GQUGMLuxLumIT8OjOBKstblAS7FZrGm0w761uUBTwbUVs0qpWEBIagQeBBrS97ktIr5Qss8ngIuAIaAbWBERT6XbLgU+lm77VET8e6XKahNXV1vD/JkNzJ9ZfhNYcRRYMUyyTWEdPQNjai+vde9g3avddPUO0DMw/iiw+rqa0VFeYzrnR2stxb6VluYCLU0F11bMylTJGsQO4JSI6JZUAB6SdE9EPJzZ56aIuBZA0tnAVcDpko4FLgDeDCwE7pd0dESM/5vCDnjZUWCHzy3/uB07h9jaO0hX3+DI/SrZMMmue/aV7Unnft8gQ+P12FPssC/sEiCtJR33rq3YdFaxgIiIIKkVABTSR5Tssy3zckZm+znALRGxA/iVpOeA44GfVKq8duBqqKvlkNm1HDK7/FFgEcG2/p1j7k3ZmgmYbOf9a90DrNvUTVfvIN07xu9baairye1XSZbHdtb7DnurBhXtg5BUC6wG3ghcExGP5OxzEfBnQD1wSrp6EZCtaWxM15UeuwJYAXDEEUdMatnt4CaJOWlz0pHzyj9uYOdwMoy4N7+2kg2cYqh09Q6wc5zaSvYO+2wtpTjkuNhpP7ZTv54ZHglmB4CKBkTaJLRcUgtwh6RlEbG2ZJ9rgGskfQi4DPjIBM5/HXAdQFtb2/jtCWZlqq+r4ZBZjRwya2K1le4dO0f6UnZ3h/2W7gGe39xNV88g23dTWynUquQ+lTRYikHSNDptS7FG09LkqVtscu2XUUwR0SVpFXA6sHac3W4BvpEuvwgcntm2OF1ndsCRxKzGArMaCxw+t/w77LO1la5MDSVZHnvvyi8397C1r4uu3kEGhvZ838rozY6lN0XuemPk7EbPXmz5KjmKaQEwmIZDE3Aa8OWSfY6KiHXpy7OA4vJK4CZJV5F0Uh8FPFqpsppNhb2trfQODGU67AdGmrk606DJBsuGjl46ewfZ2jc47jlra5TWSEabuYqzGZcGypxMX0tTve+yr3aVrEEcBtyY9kPUALdGxJ2SrgTaI2Il8EeS3gsMAp2kzUsR8aSkW4GngJ3ARR7BZJbUVmY01DGjoY5FLeXftzI0HGzry2/2yq7r6h3kpa5+nnppzxNNZjvt5zSN7bgfL1zcDHZwUTLY6ODX1tYW7e3tU10Ms6rSPziUjP4qqakUhxdv7RscaSLr6hsNmt3dEFlsBmsZ068ytvO+paTvZbZHg1WMpNUR0Za3zXdSm9m4Ggu1NBZqOXSCQ4x7BoYy/Smj4ZLtXyneif9SVx+dvbufbLI4GqwYHC1j7mNJ+lyy4VJ89rdD7hsHhJlNquwNkYvL+6oVYOxkk119+Z32xcDp6Bngl6/teTRYXY1GmsCyNZOWpuQGyJEZjkuGIbt/JeGAMLMDQnayyYkYHBpOm7pGO+rHC5fiLMZde9G/0tJUT8uM5Hm8PpZqmx7fAWFmB7XCXswLBmP7V4ozGXf17dok1tU7yPrXeuns3fMw46ZC7ZgaS/Gu+pZsyGT6Vw70jnsHhJlNS3vbv9KX+YbI0j6WYqd96dxgW/sGx73bHmBmQ91oTaX05sjS5rH9OOmkA8LMrEySaK6vo7m+joUTGGacncl4a2a48dbMqLCtfYNsTZdf7tq2x457gFmNdbQ0Fzj9za/jz886dhKucCwHhJlZhY2ZyXgCxxU77rNDiIuTTnaltZWtfYO8bgLf5TIRDggzswNUtuN+IpNOTtr77/+3NDOzg4EDwszMcjkgzMwslwPCzMxyOSDMzCyXA8LMzHI5IMzMLJcDwszMclXNFwZJ2gy8sA+nmA+8NknFOVhMx2uG6XndvubpY6LXfWRELMjbUDUBsa8ktY/3rUrVajpeM0zP6/Y1Tx+Ted1uYjIzs1wOCDMzy+WAGHXdVBdgCkzHa4bped2+5ulj0q7bfRBmZpbLNQgzM8vlgDAzs1zTPiAknS7pWUnPSfrcVJenEiQdLmmVpKckPSnp4nT9XEn3SVqXPrdOdVkrQVKtpCck3Zm+XirpkfQz/66k+qku42SS1CLpNknPSHpa0jumw2ct6U/Tn++1km6W1FiNn7WkGyRtkrQ2sy7381Xiq+n1/0zSWyfyXtM6ICTVAtcAZwDHAr8rafK/2HXq7QQuiYhjgROAi9Lr/Bzww4g4Cvhh+roaXQw8nXn9ZeArEfFGoBP42JSUqnL+D/CDiPg14C0k117Vn7WkRcCngLaIWAbUAhdQnZ/1d4DTS9aN9/meARyVPlYA35jIG03rgACOB56LiF9GxABwC3DOFJdp0kXEyxHxeLq8neQXxiKSa70x3e1G4NwpKWAFSVoMnAV8O30t4BTgtnSXqrpuSXOAdwPXA0TEQER0MQ0+a5KvUG6SVAc0Ay9ThZ91RDwIdJSsHu/zPQf4h0g8DLRIOqzc95ruAbEI2JB5vTFdV7UkLQGOAx4BDo2Il9NNrwCHTlW5Kuhq4H8Bw+nreUBXROxMX1fbZ74U2Az837RZ7duSZlDln3VEvAj8HfBfJMGwFVhNdX/WWeN9vvv0O266B8S0ImkmcDvwJxGxLbstkvHOVTXmWdIHgE0RsXqqy7If1QFvBb4REccBPZQ0J1XpZ91K8tfyUmAhMINdm2Gmhcn8fKd7QLwIHJ55vThdV3UkFUjC4Z8j4nvp6leL1c30edNUla9CTgTOlrSepPnwFJL2+Za0GQKq7zPfCGyMiEfS17eRBEa1f9bvBX4VEZsjYhD4HsnnX82fddZ4n+8+/Y6b7gHxGHBUOtKhnqRTa+UUl2nSpe3u1wNPR8RVmU0rgY+kyx8Bvr+/y1ZJEXFpRCyOiCUkn+1/RMSHgVXAb6e7VdV1R8QrwAZJb0pXnQo8RZV/1iRNSydIak5/3ovXXbWfdYnxPt+VwP9IRzOdAGzNNEXt0bS/k1rSmSTt1LXADRHxl1Nboskn6V3AfwI/Z7Qt/n+T9EPcChxBMlX6+RFR2vlVFSSdDHw6Ij4g6fUkNYq5wBPAhRGxYwqLN6kkLSfplK8Hfgl8lOSPwar+rCVdAXyQZNTeE8D/JGlvr6rPWtLNwMkk03q/CnwB+FdyPt80LL9G0tzWC3w0ItrLfq/pHhBmZpZvujcxmZnZOBwQZmaWywFhZma5HBBmZpbLAWFmZrkcEGYHAEknF2ebNTtQOCDMzCyXA8JsAiRdKOlRSWskfTP9roluSV9Jv4vgh5IWpPsul/RwOg//HZk5+t8o6X5JP5X0uKQ3pKefmfkeh39Ob3IymzIOCLMySTqG5E7dEyNiOTAEfJhkYrj2iHgz8COSO1sB/gH4bET8Osld7MX1/wxcExFvAd5JMvsoJLPs/gnJd5O8nmQuIbMpU7fnXcwsdSrwNuCx9I/7JpJJ0YaB76b7/BPwvfR7GVoi4kfp+huBf5E0C1gUEXcAREQ/QHq+RyNiY/p6DbAEeKjiV2U2DgeEWfkE3BgRl45ZKV1est/ezl+TnSNoCP//tCnmJiaz8v0Q+G1Jh8DI9wAfSfL/qDhj6IeAhyJiK9Ap6aR0/e8BP0q/0W+jpHPTczRIat6fF2FWLv+FYlamiHhK0mXAvZJqgEHgIpIv5Tk+3baJpJ8CkmmXr00DoDirKiRh8U1JV6bn+J39eBlmZfNsrmb7SFJ3RMyc6nKYTTY3MZmZWS7XIMzMLJdrEGZmlssBYWZmuRwQZmaWywFhZma5HBBmZpbr/wOO3LL9CWkmLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluations\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.778600e+04</td>\n",
       "      <td>27786.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.484177e+07</td>\n",
       "      <td>0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.099092e+08</td>\n",
       "      <td>0.068241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.075042e+02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.517275e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.768356e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.151963e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.743262e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error    true_class\n",
       "count          2.778600e+04  27786.000000\n",
       "mean           3.484177e+07      0.004679\n",
       "std            2.099092e+08      0.068241\n",
       "min            1.075042e+02      0.000000\n",
       "25%            2.517275e+05      0.000000\n",
       "50%            9.768356e+05      0.000000\n",
       "75%            2.151963e+06      0.000000\n",
       "max            2.743262e+09      1.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(df_Test_copy)\n",
    "\n",
    "mse = np.mean(np.power(df_Test_copy - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': Y_test})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to predict whether or not a new/unseen transaction is normal or fraudulent, well calculate the reconstruction error from the transaction data itself.   \n",
    "If the error is larger than a predefined threshold, well mark it as a fraud (since our model should have a low error on normal transactions).   \n",
    "Picking a value as .004 times the mean .( Chosen empirically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predictions\n",
    "threshold = (3.484177e+07)*.004\n",
    "\n",
    "\n",
    "LABELS = [\"Normal\", \"Fraud\"]\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.18      0.31     27656\n",
      "           1       0.00      0.80      0.01       130\n",
      "\n",
      "    accuracy                           0.19     27786\n",
      "   macro avg       0.50      0.49      0.16     27786\n",
      "weighted avg       0.99      0.19      0.31     27786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation \n",
    "### Not effective \n",
    "The model is predicting the fraud with a recall of 80% , but at the same time it is classifying 22576 cases as fraud which were not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
